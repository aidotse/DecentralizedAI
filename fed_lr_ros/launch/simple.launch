<?xml version="1.0"?>
<launch>

  <!-- Global parameters -->
  <arg name="learning_rate"    default="0.01" />
  <arg name="batch_size"       default="32"   />
  <arg name="epochs"           default="10"   doc="Training epochs for each communcation round." />
  <arg name="comm_rounds"      default="15"   doc="Total number of communcation rounds." />

  <!-- Dataset loader -->	
  <node name="dataset_node" pkg="fed_lr_ros" type="dataset.py" output="screen" />

  <!-- Federated server -->	
  <node name="server_node" pkg="fed_lr_ros" type="server.py" output="screen">
    <param name="comm_rounds" type="int" value="$(arg comm_rounds)" />
  </node>
  
  <!-- Federated client(s) -->
  <!-- Note: name must be unique for each client -->

  <!-- CLient A -->
  <node name="client_a_node" pkg="fed_lr_ros" type="client.py" output="screen">
    <param name="learning_rate" type="double" value="$(arg learning_rate)" />
    <param name="batch_size"    type="int"    value="$(arg batch_size)" />
    <param name="epochs"        type="int"    value="$(arg epochs)" />
    <param name="dataset_percentage" type="double" value="0.1" />
  </node>

  <!-- CLient B -->
  <node name="client_b_node" pkg="fed_lr_ros" type="client.py" output="screen">
    <param name="learning_rate" type="double" value="$(arg learning_rate)" />
    <param name="batch_size"    type="int"    value="$(arg batch_size)" />
    <param name="epochs"        type="int"    value="$(arg epochs)" />
    <param name="dataset_percentage" type="double" value="0.1" />
  </node>

</launch>
